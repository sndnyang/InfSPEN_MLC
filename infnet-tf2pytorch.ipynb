{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85d527e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:08:10.809216Z",
     "start_time": "2021-05-28T05:08:10.758854Z"
    }
   },
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b532da",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4567bd39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:08:13.054493Z",
     "start_time": "2021-05-28T05:08:11.727883Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "gpu = \"\"\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "\n",
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "\n",
    "tf.enable_eager_execution(tf_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dd30b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:10:33.873198Z",
     "start_time": "2021-05-28T05:10:33.619168Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import munch\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import data_loader.data_generator as data_generator\n",
    "from data_loader.data_generator import load_embeddings, load_vocab\n",
    "from models.spen import SPEN\n",
    "from trainers.spen_trainer import SpenTrainer\n",
    "from utils.config import process_config\n",
    "from utils.dirs import create_dirs\n",
    "from utils.logger import get_logger, TFLogger\n",
    "from utils.utils import get_args\n",
    "from models.init import weight_init_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e28f0f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:16:36.120492Z",
     "start_time": "2021-05-28T05:16:36.066282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = argparse.Namespace()\n",
    "args.seed = 1\n",
    "args.config = 'configs/bibtex.json'\n",
    "np.random.seed(args.seed)\n",
    "tf.set_random_seed(args.seed)\n",
    "config = process_config(args.config)\n",
    "config.summary_dir = 'debug_tf2torch_summary'\n",
    "config.checkpoint_dir = 'debug_tf2torch_checkpoint'\n",
    "create_dirs([config.summary_dir, config.checkpoint_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1400c91",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de70cf23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:10:40.052064Z",
     "start_time": "2021-05-28T05:10:39.449139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set loaded :- %d instances 4880\n",
      "dev set loaded :- %d instances 2515\n",
      "test set loaded :- %d instances 2515\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(args.seed)\n",
    "tf.set_random_seed(args.seed)\n",
    "\n",
    "generator = eval(\"data_generator.%s\" % config.data.data_generator)\n",
    "\n",
    "dsplits = config.data.splits\n",
    "train_data = generator(config, split=dsplits[0])\n",
    "print(\"training set loaded :- %d instances\", train_data.len)\n",
    "dev_data = generator(config, split=dsplits[1])\n",
    "print(\"dev set loaded :- %d instances\", dev_data.len)\n",
    "test_data = generator(config, split=dsplits[2])\n",
    "print(\"test set loaded :- %d instances\", test_data.len)\n",
    "\n",
    "#%%\n",
    "\n",
    "with open('data/bibtex/train.pickle', \"rb\") as f:\n",
    "    temp = pickle.load(f)\n",
    "    data_x = np.array([instance['feats'] for instance in temp])\n",
    "    data_y = np.array([instance['types'] for instance in temp])\n",
    "\n",
    "#%%\n",
    "\n",
    "with open('data/bibtex/test.pickle', \"rb\") as f:\n",
    "    temp = pickle.load(f)\n",
    "    test_x = np.array([instance['feats'] for instance in temp])\n",
    "    test_y = np.array([instance['types'] for instance in temp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128ce8a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:14:00.136031Z",
     "start_time": "2021-05-28T05:14:00.049887Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xyang2/project/research/audioclf/venv/lib64/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_x = torch.FloatTensor(data_x).to(device)\n",
    "data_y = torch.FloatTensor(data_y).to(device)\n",
    "test_x = torch.FloatTensor(test_x).to(device)\n",
    "test_y = torch.FloatTensor(test_y).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccc437b",
   "metadata": {},
   "source": [
    "# load models to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e71e10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T07:13:46.372079Z",
     "start_time": "2021-05-28T07:13:44.906953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105516296229916 0.3304564718587311\n",
      "0.4105516296229916 0.3304564718587311\n"
     ]
    }
   ],
   "source": [
    "def tf2torch(checkpoint, feat_net, inf_net, energy_net):\n",
    "    \n",
    "    tf_path = os.path.abspath(checkpoint)\n",
    "    init_vars = tf.train.list_variables(tf_path)\n",
    "\n",
    "    tf_vars = []\n",
    "    for name, shape in init_vars:\n",
    "        # print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "        array = tf.train.load_variable(tf_path, name)\n",
    "        tf_vars.append((name, array.squeeze()))\n",
    "    \n",
    "    feat_i = 12\n",
    "    energy_i = 8\n",
    "    inf_i = 18\n",
    "    feat_net.layer1.bias.data = torch.from_numpy(tf_vars[feat_i][1].T)\n",
    "    feat_net.layer1.weight.data = torch.from_numpy(tf_vars[feat_i + 1][1].T)\n",
    "    feat_net.layer2.bias.data = torch.from_numpy(tf_vars[feat_i + 2][1].T)\n",
    "    feat_net.layer2.weight.data = torch.from_numpy(tf_vars[feat_i + 3][1].T)\n",
    "    \n",
    "    energy_net.C1.bias.data = torch.from_numpy(tf_vars[energy_i][1].T)\n",
    "    energy_net.C1.weight.data = torch.from_numpy(tf_vars[energy_i + 1][1].T)\n",
    "    energy_net.c2.weight.data = torch.from_numpy(tf_vars[energy_i + 2][1].T)\n",
    "    energy_net.linear_wt.weight.data = torch.from_numpy(tf_vars[energy_i + 3][1].T)\n",
    "\n",
    "\n",
    "    inf_net.layer1.bias.data = torch.from_numpy(tf_vars[inf_i][1].T)\n",
    "    inf_net.layer1.weight.data = torch.from_numpy(tf_vars[inf_i + 1][1].T)\n",
    "    inf_net.layer2.bias.data = torch.from_numpy(tf_vars[inf_i + 2][1].T)\n",
    "    inf_net.layer2.weight.data = torch.from_numpy(tf_vars[inf_i + 3][1].T)\n",
    "    inf_net.layer3.weight.data = torch.from_numpy(tf_vars[inf_i + 4][1].T)\n",
    "    \n",
    "    return feat_net, inf_net, energy_net\n",
    "\n",
    "feat_net1 = MLP()\n",
    "inf_net1 = InfNet()\n",
    "energy_net1 = EnergyNet()\n",
    "feat_net1, inf_net1, energy_net1 = tf2torch('./copied.ckpt', feat_net1, inf_net1, energy_net1)\n",
    "with torch.no_grad():\n",
    "    pred_test = inf_net1(test_x)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    feat = feat_net1(test_x)\n",
    "    _, pred_test = energy_net1(feat, test_y)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "661454ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T07:04:56.592828Z",
     "start_time": "2021-05-28T07:04:55.023392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4084047359374391 0.3278044250686946\n",
      "0.4105516296229916 0.33045647185873117\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f53ea752",
   "metadata": {},
   "source": [
    "# load copied models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb8a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:18:10.016268Z",
     "start_time": "2021-05-28T05:18:09.821267Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = './copied.ckpt'\n",
    "tf_path = os.path.abspath(checkpoint)\n",
    "init_vars = tf.train.list_variables(tf_path)\n",
    "\n",
    "tf_vars = []\n",
    "for name, shape in init_vars:\n",
    "    print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "    array = tf.train.load_variable(tf_path, name)\n",
    "    tf_vars.append((name, array.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a212a1e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:23:48.409441Z",
     "start_time": "2021-05-28T05:23:48.345700Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 model/copy_inference_net/layer1/bias\n",
      "1 model/copy_inference_net/layer1/kernel\n",
      "2 model/copy_inference_net/layer2/bias\n",
      "3 model/copy_inference_net/layer2/kernel\n",
      "4 model/copy_inference_net/layer3/kernel\n",
      "5 model/cur_epoch/cur_epoch_0\n",
      "6 model/cur_epoch/cur_epoch_1\n",
      "7 model/cur_epoch/cur_epoch_2\n",
      "8 model/energy_net/label_energy1/bias\n",
      "9 model/energy_net/label_energy1/kernel\n",
      "10 model/energy_net/label_energy2/kernel\n",
      "11 model/energy_net/linear_wt\n",
      "12 model/feature_net/layer1/bias\n",
      "13 model/feature_net/layer1/kernel\n",
      "14 model/feature_net/layer2/bias\n",
      "15 model/feature_net/layer2/kernel\n",
      "16 model/global_step/global_step\n",
      "17 model/global_step/global_step_inf\n",
      "18 model/inference_net/layer1/bias\n",
      "19 model/inference_net/layer1/kernel\n",
      "20 model/inference_net/layer2/bias\n",
      "21 model/inference_net/layer2/kernel\n",
      "22 model/inference_net/layer3/kernel\n",
      "59 model/phi_opt/beta1_power\n",
      "60 model/phi_opt/beta2_power\n",
      "61 model/pretrain_feats/beta1_power\n",
      "62 model/pretrain_feats/beta2_power\n",
      "63 model/psi_opt/beta1_power\n",
      "64 model/psi_opt/beta2_power\n",
      "65 model/theta_opt/beta1_power\n",
      "66 model/theta_opt/beta2_power\n"
     ]
    }
   ],
   "source": [
    "for i, (name, shape) in enumerate(init_vars):\n",
    "    if 'Adam' in name:\n",
    "        continue\n",
    "    print(i, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a4c78b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:15:01.282251Z",
     "start_time": "2021-05-28T05:15:01.226284Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_map(y, pred, threshold=None):\n",
    "    if threshold is None:\n",
    "        threshold = [0.05, 0.10, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "    else:\n",
    "        threshold = [0.5]\n",
    "    best_f1 = 0\n",
    "    for t in threshold:\n",
    "        local_pred = pred > t\n",
    "        local_f1 = f1_score(y.data.cpu().numpy(), local_pred.data.cpu().numpy(), average='samples')\n",
    "        if local_f1 > best_f1:\n",
    "            best_f1 = local_f1\n",
    "    precision = np.mean(metrics.average_precision_score(\n",
    "        y.data.cpu().numpy(), pred.data.cpu().numpy(), average=None\n",
    "    ))\n",
    "\n",
    "    return best_f1, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb5c0451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T07:08:40.757959Z",
     "start_time": "2021-05-28T07:08:40.681456Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2ebe63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T08:08:44.299919Z",
     "start_time": "2021-05-28T08:08:43.403843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105516296229916 0.3304564718587311\n",
      "{'base_objective': 0.8605382442474365, 'base_obj_real': -1.0311719179153442, 'energy_inf_net': -3.121706962585449, 'energy_ground_truth': -4.839284420013428, 'reg_losses_theta': 373.61114501953125, 'reg_losses_phi': 1181.28125, 'reg_losses_entropy': 0.028994059190154076, 'pretrain_bias': 0.0}\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(1836, 150)\n",
    "        self.layer2 = nn.Linear(150, 150)      \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = func.relu(self.layer1(x))\n",
    "        out = func.relu(self.layer2(out))\n",
    "        return out\n",
    "\n",
    "class EnergyNet(nn.Module):\n",
    "    def __init__(self, weights_last_layer_mlp=150, feature_dim=150, label_dim=159,\n",
    "                 num_pairwise=16, non_linearity=nn.Softplus()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.non_linearity = non_linearity\n",
    "\n",
    "        self.linear_wt = nn.Linear(150, label_dim, bias=False) \n",
    "\n",
    "        # Label energy terms, C1/c2  in equation 5 of SPEN paper\n",
    "        self.C1 = nn.Linear(label_dim, num_pairwise)\n",
    "\n",
    "        self.c2 = nn.Linear(num_pairwise, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Local energy\n",
    "        negative_logits = self.linear_wt(x)\n",
    "        feat_probs = torch.sigmoid(-1 * negative_logits)\n",
    "        \n",
    "        # element-wise product\n",
    "        e_local = torch.mul(negative_logits, y)\n",
    "        e_local = torch.sum(e_local, dim=1)\n",
    "\n",
    "        # Label energy\n",
    "        e_label = self.non_linearity(self.C1(y))\n",
    "        e_label = self.c2(e_label)\n",
    "        e_global = torch.add(e_label, e_local)\n",
    "\n",
    "        return e_global, feat_probs\n",
    "    \n",
    "\n",
    "    \n",
    "class InfNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(1836, 150)\n",
    "        self.layer2 = nn.Linear(150, 150)\n",
    "        self.layer3 = nn.Linear(150, 159, bias=False) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = func.relu(self.layer1(x))\n",
    "        out = func.relu(self.layer2(out))\n",
    "        out = self.layer3(out)\n",
    "        return torch.sigmoid(out)\n",
    "    \n",
    "class SPEN():\n",
    "    def __init__(self, feature_net, energy_net, inf_net, n_steps_inf=1, input_dim=1836, label_dim=159):\n",
    "        self.feature_extractor = feature_net\n",
    "        self.feature_extractor.eval()\n",
    "        self.energy_net = energy_net\n",
    "        self.inf_net = inf_net\n",
    "        \n",
    "        self.phi0 = InfNet().to(device)\n",
    "        self.phi0.load_state_dict(inf_net.state_dict())\n",
    "        \n",
    "    def _compute_energy(self, inputs, targets):\n",
    "        f_x = self.feature_extractor(inputs)\n",
    "        \n",
    "        # Energy ground truth\n",
    "        gt_energy, _ = self.energy_net(f_x, targets)\n",
    "        \n",
    "        # Cost-augmented inference network\n",
    "        pred_probs = self.inf_net(inputs)\n",
    "        \n",
    "        pred_energy, _ = self.energy_net(f_x, pred_probs)\n",
    "        \n",
    "        return pred_probs, pred_energy, gt_energy\n",
    "    \n",
    "    def compute_loss(self, inputs, targets):\n",
    "        \n",
    "        pred_probs, pred_energy, gt_energy = self._compute_energy(inputs, targets)\n",
    "        # Max-margin Loss\n",
    "        delta = torch.sum((pred_probs - targets)**2, dim=1)\n",
    "        pre_loss_real = delta - pred_energy + gt_energy\n",
    "        \n",
    "        energy_loss = torch.relu(pre_loss_real)\n",
    "        pre_loss_real = torch.mean(pre_loss_real)\n",
    "        energy_loss = torch.mean(energy_loss)\n",
    "\n",
    "        entropy_loss = nn.BCELoss()(pred_probs, pred_probs.detach())\n",
    "        \n",
    "        reg_losses_phi = 0.5 * sum(p.pow(2.0).sum() for p in self.inf_net.parameters())\n",
    "        pretrain_bias = 0.5 * sum((x - y).pow(2.0).sum() for x, y in zip(self.inf_net.state_dict().values(), self.phi0.state_dict().values()))\n",
    "        reg_losses_theta = sum(p.pow(2.0).sum() for p in self.energy_net.parameters())\n",
    "        \n",
    "        inf_net_loss = energy_loss \\\n",
    "                       - 0.001 * reg_losses_phi\\\n",
    "                       - 1 * pretrain_bias \\\n",
    "                       - 1 * entropy_loss\n",
    "        inf_net_loss = -inf_net_loss\n",
    "        \n",
    "        e_net_loss = energy_loss + 0.001 * reg_losses_theta\n",
    "        \n",
    "        summaries = {\n",
    "            'base_objective': energy_loss.item(),\n",
    "            'base_obj_real': pre_loss_real.item(),\n",
    "            'energy_inf_net': pred_energy.mean().item(),\n",
    "            'energy_ground_truth': gt_energy.mean().item(),\n",
    "            'reg_losses_theta': reg_losses_theta.item(),\n",
    "            'reg_losses_phi': reg_losses_phi.item(),\n",
    "            'reg_losses_entropy': entropy_loss.item(),\n",
    "            'pretrain_bias': pretrain_bias.item()\n",
    "        }\n",
    "        print(summaries)\n",
    "        \n",
    "        return pred_probs, e_net_loss, inf_net_loss\n",
    "\n",
    "    def pred(self, x):\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.inf_net(x)\n",
    "        return y_pred\n",
    "    \n",
    "    def inference(self, x, training=False, n_steps=1):\n",
    "        \n",
    "        sd = self.inf_net.state_dict()\n",
    "        inf_net2 = MLP()\n",
    "        inf_net2.load_state_dict(sd)\n",
    "        self.inf_net.eval()\n",
    "        optimizer = optim.SGD(self.inf_net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.inf_net(x)\n",
    "        \n",
    "        self.inf_net.train()\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "feat_net1 = MLP()\n",
    "inf_net1 = InfNet()\n",
    "energy_net1 = EnergyNet()\n",
    "feat_net1, inf_net1, energy_net1 = tf2torch('./copied.ckpt', feat_net1, inf_net1, energy_net1)\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)\n",
    "\n",
    "spen = SPEN(feat_net1, energy_net1, inf_net1)\n",
    "preds, e_loss, inf_loss = spen.compute_loss(data_x[:32], data_y[:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31c5e9d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:31:47.002529Z",
     "start_time": "2021-05-28T05:31:46.943573Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0eca7c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T08:00:22.227672Z",
     "start_time": "2021-05-28T08:00:22.172390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2362.5625, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.pow(2.0).sum() for p in inf_net1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65d3ce14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T07:31:30.947172Z",
     "start_time": "2021-05-28T07:31:29.497876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105516296229916 0.3304564718587311\n",
      "torch.Size([2515, 159])\n",
      "torch.Size([2515])\n",
      "torch.Size([2515, 15])\n",
      "torch.Size([2515])\n",
      "torch.Size([2515])\n",
      "0.4105516296229916 0.3304564718587311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(1836, 150)\n",
    "        self.layer2 = nn.Linear(150, 150)      \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = func.relu(self.layer1(x))\n",
    "        out = func.relu(self.layer2(out))\n",
    "        return out\n",
    "\n",
    "class EnergyNet(nn.Module):\n",
    "    def __init__(self, weights_last_layer_mlp=150, feature_dim=150, label_dim=159,\n",
    "                 num_pairwise=16, non_linearity=nn.Softplus()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.non_linearity = non_linearity\n",
    "\n",
    "        self.linear_wt = nn.Linear(150, label_dim, bias=False) \n",
    "\n",
    "        # Label energy terms, C1/c2  in equation 5 of SPEN paper\n",
    "        self.C1 = nn.Linear(label_dim, num_pairwise)\n",
    "\n",
    "        self.c2 = nn.Linear(num_pairwise, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Local energy\n",
    "        negative_logits = self.linear_wt(x)\n",
    "        feat_probs = torch.sigmoid(-1 * negative_logits)\n",
    "        \n",
    "        # element-wise product\n",
    "        e_local = torch.mul(negative_logits, y)\n",
    "        print(e_local.shape)\n",
    "        e_local = torch.sum(e_local, dim=1)\n",
    "        print(e_local.shape)\n",
    "\n",
    "        # Label energy\n",
    "        e_label = self.non_linearity(self.C1(y))\n",
    "        print(e_label.shape)\n",
    "        e_label = self.c2(e_label)\n",
    "        print(e_label.shape)\n",
    "        e_global = torch.add(e_label, e_local)\n",
    "        print(e_global.shape)\n",
    "\n",
    "        return e_global, feat_probs\n",
    "    \n",
    "feat_net1 = MLP()\n",
    "inf_net1 = InfNet()\n",
    "energy_net = EnergyNet()\n",
    "feat_net1, inf_net1, energy_net = tf2torch('./copied.ckpt', feat_net1, inf_net1, energy_net)\n",
    "with torch.no_grad():\n",
    "    pred_test = inf_net1(test_x)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    feat = feat_net1(test_x)\n",
    "    _, pred_test = energy_net(feat, test_y)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a47c279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T07:15:07.184008Z",
     "start_time": "2021-05-28T07:15:05.715696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105516296229916 0.3304564718587311\n",
      "0.4105516296229916 0.3304564718587311\n"
     ]
    }
   ],
   "source": [
    "feat_net1 = MLP()\n",
    "inf_net1 = InfNet()\n",
    "energy_net1 = EnergyNet()\n",
    "feat_net1, inf_net1, energy_net1 = tf2torch('./copied.ckpt', feat_net1, inf_net1, energy_net1)\n",
    "with torch.no_grad():\n",
    "    pred_test = inf_net1(test_x)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    feat = feat_net1(test_x)\n",
    "    _, pred_test = energy_net1(feat, test_y)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53e74ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T07:15:25.275585Z",
     "start_time": "2021-05-28T07:15:24.489783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105516296229916 0.3304564718587311\n"
     ]
    }
   ],
   "source": [
    "spen = SPEN(feat_net1, energy_net1, inf_net1)\n",
    "preds, e_loss, inf_loss = spen.compute_loss(data, label)\n",
    "pred_test = spen.pred(test_x)\n",
    "best_f1, mAP = f1_map(test_y, pred_test)\n",
    "print(best_f1, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c3591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d787e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7432dfb",
   "metadata": {},
   "source": [
    "# cost trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f947fb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:50:32.154268Z",
     "start_time": "2021-05-28T05:50:31.244443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4084047359374391 0.3278044250686946\n"
     ]
    }
   ],
   "source": [
    "feat_net2 = MLP()\n",
    "inf_net2 = MLP()\n",
    "feat_net2, inf_net2, _ = tf2torch('./cost.ckpt', feat_net2, inf_net2, None)\n",
    "with torch.no_grad():\n",
    "    pred_test = inf_net2(test_x, pretrain=False)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251a3f0",
   "metadata": {},
   "source": [
    "# best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afa8a79e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:50:06.047525Z",
     "start_time": "2021-05-28T05:50:04.432303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4186186497693001 0.3267193167443796\n",
      "0.4105516296229916 0.33045647185873117\n"
     ]
    }
   ],
   "source": [
    "feat_net2 = MLP()\n",
    "inf_net2 = MLP()\n",
    "feat_net2, inf_net2, _ = tf2torch('./best.ckpt', feat_net2, inf_net2, None)\n",
    "with torch.no_grad():\n",
    "    pred_test = inf_net2(test_x, pretrain=False)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_test = feat_net2(test_x)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9ff726",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1221582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T05:36:34.676362Z",
     "start_time": "2021-05-28T05:36:33.832689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39316385186990854 0.32959706166709757\n"
     ]
    }
   ],
   "source": [
    "feat_net1 = MLP()\n",
    "inf_net1 = MLP()\n",
    "feat_net1, inf_net1, _ = tf2torch('./final.ckpt', feat_net1, inf_net1, None)\n",
    "with torch.no_grad():\n",
    "    pred_test = inf_net1(test_x)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
