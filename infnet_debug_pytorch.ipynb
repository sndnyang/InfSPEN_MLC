{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f10e3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:11:47.297362Z",
     "start_time": "2021-06-18T07:11:47.261180Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3f3cc56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:11:49.463841Z",
     "start_time": "2021-06-18T07:11:47.417979Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xyang2/project/research/audioclf/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# t.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d8d01",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3764cd64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:35:49.312088Z",
     "start_time": "2021-06-18T22:35:48.972917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xyang2/project/research/audioclf/infnet-spen\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "58a4f414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:35:40.523679Z",
     "start_time": "2021-06-18T22:35:39.834240Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/bibtex/train.pickle', \"rb\") as f:\n",
    "    temp = pickle.load(f)\n",
    "    data_x = np.array([instance['feats'] for instance in temp])\n",
    "    data_y = np.array([instance['types'] for instance in temp])\n",
    "\n",
    "\n",
    "with open('data/bibtex/test.pickle', \"rb\") as f:\n",
    "    temp = pickle.load(f)\n",
    "    test_x = np.array([instance['feats'] for instance in temp])\n",
    "    test_y = np.array([instance['types'] for instance in temp])\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data_x = torch.FloatTensor(data_x).to(device)\n",
    "data_y = torch.FloatTensor(data_y).to(device)\n",
    "test_x = torch.FloatTensor(test_x).to(device)\n",
    "test_y = torch.FloatTensor(test_y).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb579b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:11:54.050973Z",
     "start_time": "2021-06-18T07:11:54.021942Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_map(y, pred, threshold=None):\n",
    "    if threshold is None:\n",
    "        threshold = [0.05, 0.10, 0.15, 0.2, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.60, 0.65, 0.70, 0.75]\n",
    "    else:\n",
    "        threshold = [0.5]\n",
    "    best_f1 = 0\n",
    "    for t in threshold:\n",
    "        local_pred = pred > t\n",
    "        local_f1 = f1_score(y.data.cpu().numpy(), local_pred.data.cpu().numpy(), average='samples')\n",
    "        if local_f1 > best_f1:\n",
    "            best_f1 = local_f1\n",
    "    precision = np.mean(metrics.average_precision_score(\n",
    "        y.data.cpu().numpy(), pred.data.cpu().numpy(), average=None\n",
    "    ))\n",
    "\n",
    "    return best_f1, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed3e46",
   "metadata": {},
   "source": [
    "# Arch s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e20f3d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:11:54.217298Z",
     "start_time": "2021-06-18T07:11:54.052460Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(1836, 150)\n",
    "        self.layer2 = nn.Linear(150, 150)      \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = func.relu(self.layer1(x))\n",
    "        out = func.relu(self.layer2(out))\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452b7ec1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:16:15.307750Z",
     "start_time": "2021-06-18T07:16:06.700005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "0.010612515383887152 0.03239640349215638\n",
      "\n",
      "epoch 1\n",
      "0.14521789895547352 0.0950389308766338\n",
      "\n",
      "epoch 2\n",
      "0.19718947498271552 0.14722309977371306\n",
      "\n",
      "epoch 3\n",
      "0.21832717977847202 0.19360340578231233\n",
      "\n",
      "epoch 4\n",
      "0.243371832497081 0.23144460515764315\n",
      "\n",
      "epoch 5\n",
      "0.26413997312605664 0.26450110012015443\n",
      "\n",
      "epoch 6\n",
      "0.28348104292438286 0.28794679487069746\n",
      "\n",
      "epoch 7\n",
      "0.30611502210764224 0.3012620973138103\n",
      "\n",
      "epoch 8\n",
      "0.3315541749590091 0.3099285562858436\n",
      "\n",
      "epoch 9\n",
      "0.3401557106699934 0.3119738275330926\n",
      "\n",
      "epoch 10\n",
      "0.3453505929613987 0.31223580932536793\n",
      "\n",
      "epoch 11\n",
      "0.3490278477271688 0.31247202677472735\n",
      "\n",
      "epoch 12\n",
      "0.35557245319409175 0.31088071957103347\n",
      "\n",
      "epoch 13\n",
      "0.36646074427124964 0.31017692004801145\n",
      "\n",
      "epoch 14\n",
      "0.3567290072391968 0.31047401359604065\n",
      "\n",
      "epoch 15\n",
      "0.36200591356304135 0.3072352959550528\n",
      "\n",
      "epoch 16\n",
      "0.3708267047730268 0.30712782849428355\n",
      "\n",
      "epoch 17\n",
      "0.35581687696001807 0.30150322231006416\n",
      "\n",
      "epoch 18\n",
      "0.3709799706004828 0.30132950077515375\n",
      "\n",
      "epoch 19\n",
      "0.3712019472620572 0.3008649561447038\n",
      "\n",
      "0.39986122455594064 0.3008649561447038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feat_net = MLP().to(device)\n",
    "energy_net = EnergyNet().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(list(feat_net.parameters()) + list(energy_net.parameters()), lr=1e-3, weight_decay=0)\n",
    "\n",
    "for epoch in range(20):\n",
    "    inds = np.random.permutation(list(range(len(data_x))))\n",
    "    for i in range(0, 4880, 32):\n",
    "        l = inds[i:i+32]\n",
    "        data = data_x[l]\n",
    "        label = data_y[l]\n",
    "        feat = feat_net(data)\n",
    "        _, logits = energy_net(feat, label)\n",
    "        loss = criterion(logits, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch', epoch)\n",
    "    with torch.no_grad():\n",
    "        feat = feat_net(test_x)\n",
    "        _, pred_test = energy_net(feat, test_y)\n",
    "    \n",
    "    best_f1, mAP = f1_map(test_y, pred_test, 0.5)\n",
    "    print(best_f1, mAP)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7375d6d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:16:15.937222Z",
     "start_time": "2021-06-18T07:16:15.309499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.4456,  7.1403, 12.4506,  ...,  4.6460,  4.8572,  4.4169],\n",
      "        [ 8.0281,  0.9246, 10.6162,  ...,  8.0007,  6.3127,  0.8347],\n",
      "        [ 1.9766,  5.8080,  3.7858,  ...,  3.8194,  1.6761,  4.8637],\n",
      "        ...,\n",
      "        [ 0.6951,  2.3739,  9.3303,  ...,  4.7144,  2.0970,  0.6466],\n",
      "        [ 4.8289,  0.9531, 13.5373,  ...,  9.1066,  3.6389,  0.0000],\n",
      "        [ 6.3641,  4.8654, 14.8546,  ..., 11.9688,  6.9226,  3.9216]],\n",
      "       device='cuda:0')\n",
      "0.39986122455594064 0.3008649561447038\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    feat = feat_net(test_x)\n",
    "    print(feat)\n",
    "    _, pred_test = energy_net(feat, test_y)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1106de4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:16:15.962847Z",
     "start_time": "2021-06-18T07:16:15.938967Z"
    }
   },
   "outputs": [],
   "source": [
    "class InfNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(1836, 150)\n",
    "        self.layer2 = nn.Linear(150, 150)\n",
    "        self.layer3 = nn.Linear(150, 159, bias=False) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = func.relu(self.layer1(x))\n",
    "        out = func.relu(self.layer2(out))\n",
    "        out = self.layer3(out)\n",
    "        return torch.sigmoid(out), out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a826803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:16:04.835896Z",
     "start_time": "2021-06-18T07:16:04.808214Z"
    }
   },
   "outputs": [],
   "source": [
    "class EnergyNet(nn.Module):\n",
    "    def __init__(self, weights_last_layer_mlp=150, feature_dim=150, label_dim=159,\n",
    "                 num_pairwise=16, non_linearity=nn.Softplus()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.non_linearity = non_linearity\n",
    "\n",
    "        self.linear_wt = nn.Linear(150, label_dim, bias=False) \n",
    "\n",
    "        # Label energy terms, C1/c2  in equation 5 of SPEN paper\n",
    "        self.C1 = nn.Linear(label_dim, num_pairwise)\n",
    "\n",
    "        self.c2 = nn.Linear(num_pairwise, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Local energy\n",
    "        negative_logits = self.linear_wt(x)\n",
    "        feat_probs = torch.sigmoid(-1 * negative_logits)\n",
    "        \n",
    "        # element-wise product\n",
    "        e_local = torch.mul(negative_logits, y)\n",
    "        e_local = torch.sum(e_local, dim=1)\n",
    "\n",
    "        # Label energy\n",
    "        e_label = self.non_linearity(self.C1(y))\n",
    "        e_label = self.c2(e_label)\n",
    "        assert e_label.view(-1).shape[0] == e_label.shape[0]\n",
    "        assert e_label.view(-1).shape[0] == e_local.shape[0]\n",
    "        e_global = torch.add(e_label.view(-1), e_local.view(-1))\n",
    "\n",
    "        return e_global, feat_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19446910",
   "metadata": {},
   "source": [
    "# train cost inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae2ed14e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:19:06.685642Z",
     "start_time": "2021-06-18T07:19:05.331130Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4105516296229916 0.3304564718587311\n",
      "0.4105516296229916 0.3304564718587311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tf2torch(checkpoint, feat_net, inf_net, energy_net):\n",
    "    \n",
    "    tf_path = os.path.abspath(checkpoint)\n",
    "    init_vars = tf.train.list_variables(tf_path)\n",
    "\n",
    "    tf_vars = []\n",
    "    for name, shape in init_vars:\n",
    "        # print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "        array = tf.train.load_variable(tf_path, name)\n",
    "        tf_vars.append((name, array.squeeze()))\n",
    "    \n",
    "    feat_i = 12\n",
    "    energy_i = 8\n",
    "    inf_i = 18\n",
    "    feat_net.layer1.bias.data = torch.from_numpy(tf_vars[feat_i][1].T)\n",
    "    feat_net.layer1.weight.data = torch.from_numpy(tf_vars[feat_i + 1][1].T)\n",
    "    feat_net.layer2.bias.data = torch.from_numpy(tf_vars[feat_i + 2][1].T)\n",
    "    feat_net.layer2.weight.data = torch.from_numpy(tf_vars[feat_i + 3][1].T)\n",
    "    \n",
    "    energy_net.C1.bias.data = torch.from_numpy(tf_vars[energy_i][1].T)\n",
    "    energy_net.C1.weight.data = torch.from_numpy(tf_vars[energy_i + 1][1].T)\n",
    "    energy_net.c2.weight.data = torch.from_numpy(tf_vars[energy_i + 2][1].T)\n",
    "    energy_net.linear_wt.weight.data = torch.from_numpy(tf_vars[energy_i + 3][1].T)\n",
    "\n",
    "\n",
    "    inf_net.layer1.bias.data = torch.from_numpy(tf_vars[inf_i][1].T)\n",
    "    inf_net.layer1.weight.data = torch.from_numpy(tf_vars[inf_i + 1][1].T)\n",
    "    inf_net.layer2.bias.data = torch.from_numpy(tf_vars[inf_i + 2][1].T)\n",
    "    inf_net.layer2.weight.data = torch.from_numpy(tf_vars[inf_i + 3][1].T)\n",
    "    inf_net.layer3.weight.data = torch.from_numpy(tf_vars[inf_i + 4][1].T)\n",
    "    \n",
    "    return feat_net.to(device), inf_net.to(device), energy_net.to(device)\n",
    "\n",
    "feat_net1 = MLP()\n",
    "inf_net1 = InfNet()\n",
    "energy_net1 = EnergyNet()\n",
    "feat_net1, inf_net1, energy_net1 = tf2torch('./copied.ckpt', feat_net1, inf_net1, energy_net1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_test, _ = inf_net1(test_x)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    feat = feat_net1(test_x)\n",
    "    _, pred_test = energy_net1(feat, test_y)\n",
    "\n",
    "f1, mAP = f1_map(test_y, pred_test)\n",
    "print(f1, mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0644f",
   "metadata": {},
   "source": [
    "# print different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c929d7bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:16:23.834732Z",
     "start_time": "2021-06-18T07:16:23.806436Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_model(feat_net, inf_net, energy_net):\n",
    "    for t in feat_net.named_parameters():\n",
    "        print(t[0], ':', '%.6f' % t[1].sum().item())\n",
    "    for t in inf_net.named_parameters():\n",
    "        print(t[0], ':', '%.6f' % t[1].sum().item())\n",
    "    for t in energy_net.named_parameters():\n",
    "        print(t[0], ':', '%.6f' % t[1].sum().item())\n",
    "\n",
    "        \n",
    "def print_model_grad(feat_net, inf_net, energy_net):\n",
    "    for t in feat_net.named_parameters():\n",
    "        print('feat_net/' + t[0], ':', '%9.6f' % t[1].grad.sum().item(), '%.6f' % t[1].sum().item())\n",
    "    for t in inf_net.named_parameters():\n",
    "        print('infer_net/' + t[0], ':', '%9.6f' % t[1].grad.sum().item(), '%.6f' % t[1].sum().item())\n",
    "    for t in energy_net.named_parameters():\n",
    "        print('energy_net/' + t[0], ':', '%9.6f' % t[1].grad.sum().item(), '%.6f' % t[1].sum().item())\n",
    "\n",
    "def print_energy_grad(energy_net):\n",
    "    for t in energy_net.named_parameters():\n",
    "        print('energy_net/' + t[0], ':', '%9.6f' % t[1].grad.sum().item(), '%.6f' % t[1].sum().item())\n",
    "        \n",
    "def print_grads(grads):\n",
    "    for g in grads:\n",
    "        print('grads: ', g.sum().item())\n",
    "        \n",
    "def print_summary(summary, j):\n",
    "    print('iter %d:  cost_phi %.7f' % (j, summary['infer cost']))\n",
    "    # print('cost_theta %.7f' % summary['energy cost'])\n",
    "    # print('base_obj %.7f' % summary['base_objective'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52af30",
   "metadata": {},
   "source": [
    "# SPEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87e2646c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:30:23.982257Z",
     "start_time": "2021-06-18T07:30:23.955090Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "l = np.arange(i, i+32)\n",
    "data = data_x[l]\n",
    "label = data_y[l]\n",
    "\n",
    "i = 32\n",
    "l = np.arange(i, i+32)\n",
    "data2 = data_x[l]\n",
    "label2 = data_y[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a73d8d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:17:26.956919Z",
     "start_time": "2021-06-18T07:17:26.929751Z"
    }
   },
   "outputs": [],
   "source": [
    "class EnergyNet(nn.Module):\n",
    "    def __init__(self, weights_last_layer_mlp=150, feature_dim=150, label_dim=159,\n",
    "                 num_pairwise=16, non_linearity=nn.Softplus()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.non_linearity = non_linearity\n",
    "\n",
    "        self.linear_wt = nn.Linear(150, label_dim, bias=False) \n",
    "\n",
    "        # Label energy terms, C1/c2  in equation 5 of SPEN paper\n",
    "        self.C1 = nn.Linear(label_dim, num_pairwise)\n",
    "\n",
    "        self.c2 = nn.Linear(num_pairwise, 1, bias=False)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # Local energy\n",
    "        negative_logits = self.linear_wt(x)\n",
    "        feat_probs = torch.sigmoid(-1 * negative_logits)\n",
    "        \n",
    "        # element-wise product\n",
    "        e_local = torch.mul(negative_logits, y)\n",
    "        e_local = torch.sum(e_local, dim=1)\n",
    "\n",
    "        # Label energy\n",
    "        e_label = self.non_linearity(self.C1(y))\n",
    "        e_label = self.c2(e_label)\n",
    "        assert e_label.view(-1).shape[0] == e_label.shape[0]\n",
    "        assert e_label.view(-1).shape[0] == e_local.shape[0]\n",
    "        e_global = torch.add(e_label.view(-1), e_local.view(-1))\n",
    "\n",
    "        return e_global, feat_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "64181a89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:18:49.242108Z",
     "start_time": "2021-06-18T22:18:49.163658Z"
    }
   },
   "outputs": [],
   "source": [
    "class SPEN():\n",
    "    def __init__(self, feature_net, energy_net, inf_net, n_steps_inf=1, input_dim=1836, label_dim=159):\n",
    "        self.feature_extractor = feature_net\n",
    "        self.feature_extractor.eval()\n",
    "        self.energy_net = energy_net\n",
    "        self.inf_net = inf_net\n",
    "        \n",
    "        self.phi0 = InfNet().to(device)\n",
    "        self.phi0.load_state_dict(inf_net.state_dict())\n",
    "            \n",
    "    def compute_loss(self, inputs, targets):\n",
    "        f_x = self.feature_extractor(inputs).detach()\n",
    "        \n",
    "        # Energy ground truth\n",
    "        gt_energy, _ = self.energy_net(f_x, targets)\n",
    "        \n",
    "        # Cost-augmented inference network\n",
    "        pred_probs, logits = self.inf_net(inputs)\n",
    "        \n",
    "        pred_energy, _ = self.energy_net(f_x, pred_probs)\n",
    "        \n",
    "        # Max-margin Loss\n",
    "        diff = torch.sum((pred_probs - targets)**2, dim=1)\n",
    "        gt_en = gt_energy\n",
    "        inf_en = pred_energy\n",
    "        pre_loss_real = diff  - inf_en + gt_en \n",
    "        # pre_loss_real = diff - inf_en + gt_en\n",
    "        # pre_loss_real = - inf_en + gt_en\n",
    "        \n",
    "        energy_loss = torch.relu(pre_loss_real)\n",
    "        pre_loss_real = torch.mean(pre_loss_real)\n",
    "        energy_loss = torch.mean(energy_loss)\n",
    "\n",
    "        entropy_loss = nn.BCELoss()(pred_probs, pred_probs.detach())\n",
    "#         entropy_loss = func.binary_cross_entropy_with_logits(logits, pred_probs.detach())\n",
    "        \n",
    "        reg_losses_phi = 0.5 * sum(p.pow(2.0).sum() for p in self.inf_net.parameters())\n",
    "        \n",
    "        pretrain_bias = sum((x - y).pow(2.0).sum() for x, y in zip(list(self.inf_net.parameters()), self.phi0.state_dict().values()))\n",
    "        \n",
    "        reg_losses_theta = 0.5 * sum(p.pow(2.0).sum() for p in self.energy_net.parameters())\n",
    "        \n",
    "        inf_net_loss = energy_loss  \\\n",
    "                       - 0.001 * reg_losses_phi \\\n",
    "                       - 1 * pretrain_bias  #  \\\n",
    "                       # - 1 * entropy_loss \n",
    "        \n",
    "        inf_net_loss = -inf_net_loss\n",
    "        \n",
    "        e_net_loss = energy_loss + 0.001 * reg_losses_theta\n",
    "        \n",
    "        summaries = {\n",
    "            'infer cost': inf_net_loss,\n",
    "            'energy cost': e_net_loss,\n",
    "            'base_objective': energy_loss,\n",
    "            'base_obj_real': pre_loss_real,\n",
    "            'energy_inf_net': pred_energy.mean(),\n",
    "            'energy_ground_truth': gt_energy.mean(),\n",
    "            'reg_losses_theta': reg_losses_theta,\n",
    "            'reg_losses_phi': reg_losses_phi,\n",
    "            'reg_losses_entropy': entropy_loss,\n",
    "            'pretrain_bias': pretrain_bias\n",
    "        }\n",
    "        \n",
    "        return pred_probs, e_net_loss, inf_net_loss, summaries\n",
    "\n",
    "    def pred(self, x):\n",
    "        with torch.no_grad():\n",
    "            y_pred, _ = self.inf_net(x)\n",
    "        return y_pred\n",
    "    \n",
    "    def inference_loss(self, x):\n",
    "\n",
    "        f_x = self.feature_extractor(x)\n",
    "        # inference network\n",
    "        pred_probs, logits = self.inf_net(x)\n",
    "        pred_energy, _ = self.energy_net(f_x, pred_probs)\n",
    "        \n",
    "        entropy_loss = func.binary_cross_entropy_with_logits(logits, pred_probs.detach())\n",
    "        reg_losses_phi = 0.5 * sum(p.pow(2.0).sum() for p in self.inf_net.parameters())\n",
    "        \n",
    "        inf_net_loss = torch.mean(pred_energy)  \\\n",
    "                       + 0.001 * reg_losses_phi \\\n",
    "                       + 1 * entropy_loss\n",
    "        \n",
    "        return inf_net_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921d201",
   "metadata": {},
   "source": [
    "# step debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "472769b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:44:49.743292Z",
     "start_time": "2021-06-18T07:44:49.707408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0:  cost_phi 1.1570342\n",
      "compute inf net gradients\n",
      "feat_net/layer1.weight : 17.899414 766.057251\n",
      "feat_net/layer1.bias :  0.196697 17.295366\n",
      "feat_net/layer2.weight : 19.131044 502.172089\n",
      "feat_net/layer2.bias :  0.136933 6.113752\n",
      "infer_net/layer1.weight :  7.929173 766.511963\n",
      "infer_net/layer1.bias :  0.208551 17.356606\n",
      "infer_net/layer2.weight :  9.020711 502.805725\n",
      "infer_net/layer2.bias :  0.088460 6.128996\n",
      "infer_net/layer3.weight : -10.122227 -720.555420\n",
      "energy_net/linear_wt.weight : 19.223404 719.875610\n",
      "energy_net/C1.weight :  0.004540 2.112450\n",
      "energy_net/C1.bias : -0.000532 -0.000042\n",
      "energy_net/c2.weight :  0.002886 -0.030406\n"
     ]
    }
   ],
   "source": [
    "feat_net.zero_grad()\n",
    "optim_e.zero_grad()\n",
    "optim_inf.zero_grad()\n",
    "preds, e_loss, inf_loss, summary = spen.compute_loss(data2, label2)\n",
    "print_summary(summary, 0)\n",
    "inf_loss.backward()\n",
    "print('compute inf net gradients')\n",
    "print_model_grad(feat_net, inf_net, energy_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df2a867a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:37:12.283244Z",
     "start_time": "2021-06-18T07:37:04.452993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'infer cost': tensor(1.1570, device='cuda:0', grad_fn=<NegBackward>),\n",
       " 'energy cost': tensor(0.2115, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'base_objective': tensor(0.0247, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'base_obj_real': tensor(-1.7291, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'energy_inf_net': tensor(-3.8876, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'energy_ground_truth': tensor(-5.9633, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'reg_losses_theta': tensor(186.8051, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'reg_losses_phi': tensor(1181.3073, device='cuda:0', grad_fn=<MulBackward0>),\n",
       " 'reg_losses_entropy': tensor(0.0234, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>),\n",
       " 'pretrain_bias': tensor(0.0004, device='cuda:0')}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103b23c",
   "metadata": {},
   "source": [
    "# all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2584b41a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:09:16.431760Z",
     "start_time": "2021-06-18T22:08:52.252892Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf net start 0.4105516296229916 0.33045646957084107\n",
      "0\n",
      "current inf net 0.3951645406964536 0.3183652439194566\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "1\n",
      "current inf net 0.39884343141395623 0.32234328773344706\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "2\n",
      "current inf net 0.4027456771023543 0.3243291427038416\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "3\n",
      "current inf net 0.4066585445422124 0.32528390548265845\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "4\n",
      "current inf net 0.4061004560066561 0.32584806409754813\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "5\n",
      "current inf net 0.4076676155627696 0.3269871627331186\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "6\n",
      "current inf net 0.4081970385611802 0.32743184774168776\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "7\n",
      "current inf net 0.4088775479476274 0.3282031100263219\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "8\n",
      "current inf net 0.40689603730262164 0.32757802909668715\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "9\n",
      "current inf net 0.4077304623147065 0.3272108909447864\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_net = MLP()\n",
    "inf_net = InfNet()\n",
    "energy_net = EnergyNet()\n",
    "feat_net, inf_net, energy_net = tf2torch('./copied.ckpt', feat_net, inf_net, energy_net)\n",
    "\n",
    "optim_inf = torch.optim.Adam(inf_net.parameters(), lr=1e-3, weight_decay=0)\n",
    "optim_energy = torch.optim.Adam(list(energy_net.C1.parameters()) + list(energy_net.c2.parameters()), \n",
    "                                lr=1e-3, weight_decay=0)\n",
    "optim_e  = torch.optim.Adam(list(inf_net.parameters()) + list(energy_net.parameters()), \n",
    "                                lr=1e-3, weight_decay=0)\n",
    "\n",
    "spen = SPEN(feat_net, energy_net, inf_net)\n",
    "pred_test = spen.pred(test_x)\n",
    "best_f1, mAP = f1_map(test_y, pred_test)\n",
    "print('inf net start', best_f1, mAP)\n",
    "\n",
    "phi_energies = []\n",
    "theta_energies = []\n",
    "f1s = [best_f1]\n",
    "for epoch in range(10):\n",
    "\n",
    "    for j, i in enumerate(range(0, 4880, 32)):\n",
    "        if i+32 > 4880:\n",
    "            i = 0\n",
    "        l = np.arange(i, i+32)\n",
    "        data = data_x[l]\n",
    "        # print(data.sum())\n",
    "        label = data_y[l]\n",
    "        \n",
    "        optim_e.zero_grad()\n",
    "        optim_inf.zero_grad()\n",
    "        preds, e_loss, inf_loss, summary = spen.compute_loss(data, label)\n",
    "\n",
    "        inf_loss.backward()\n",
    "\n",
    "        optim_inf.step()\n",
    "\n",
    "        \n",
    "        optim_e.zero_grad()\n",
    "        optim_inf.zero_grad()\n",
    "        preds, e_loss, inf_loss, summary = spen.compute_loss(data, label)\n",
    "        \n",
    "        e_loss.backward()\n",
    "\n",
    "        optim_energy.step()\n",
    "\n",
    "    print(epoch)\n",
    "    \n",
    "    pred_test = spen.pred(test_x)\n",
    "    best_f1, mAP = f1_map(test_y, pred_test)\n",
    "    print('current inf net', best_f1, mAP)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feat = feat_net(test_x)\n",
    "        _, pred_test = energy_net(feat, test_y)\n",
    "\n",
    "    f1, mAP = f1_map(test_y, pred_test, 0.5)\n",
    "    print('feature net', f1, mAP)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5331918b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:20:27.857650Z",
     "start_time": "2021-06-18T22:20:17.406967Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf net start 0.4105516296229916 0.33045646957084107\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_net = MLP()\n",
    "inf_net = InfNet()\n",
    "energy_net = EnergyNet()\n",
    "feat_net, inf_net, energy_net = tf2torch('./copied.ckpt', feat_net, inf_net, energy_net)\n",
    "\n",
    "optim_inf = torch.optim.Adam(inf_net.parameters(), lr=1e-3, weight_decay=0)\n",
    "optim_energy = torch.optim.Adam(list(energy_net.C1.parameters()) + list(energy_net.c2.parameters()), \n",
    "                                lr=1e-3, weight_decay=0)\n",
    "optim_e  = torch.optim.Adam(list(inf_net.parameters()) + list(energy_net.parameters()), \n",
    "                                lr=1e-3, weight_decay=0)\n",
    "\n",
    "spen = SPEN(feat_net, energy_net, inf_net)\n",
    "pred_test = spen.pred(test_x)\n",
    "best_f1, mAP = f1_map(test_y, pred_test)\n",
    "print('inf net start', best_f1, mAP)\n",
    "\n",
    "phi_energies = []\n",
    "theta_energies = []\n",
    "f1s = [best_f1]\n",
    "for epoch in range(10):\n",
    "\n",
    "    for j, i in enumerate(range(0, 4880, 32)):\n",
    "        if i+32 > 4880:\n",
    "            i = 0\n",
    "        l = np.arange(i, i+32)\n",
    "        data = data_x[l]\n",
    "        # print(data.sum())\n",
    "        label = data_y[l]\n",
    "        \n",
    "        optim_e.zero_grad()\n",
    "        optim_inf.zero_grad()\n",
    "        preds, e_loss, inf_loss, summary = spen.compute_loss(data, label)\n",
    "\n",
    "        inf_loss.backward(retain_graph=True)\n",
    "\n",
    "        optim_inf.step()\n",
    "\n",
    "        optim_e.zero_grad()        \n",
    "        e_loss.backward()\n",
    "        optim_energy.step()\n",
    "\n",
    "    print(epoch)\n",
    "    \n",
    "#     pred_test = spen.pred(test_x)\n",
    "#     best_f1, mAP = f1_map(test_y, pred_test)\n",
    "#     print('current inf net', best_f1, mAP)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         feat = feat_net(test_x)\n",
    "#         _, pred_test = energy_net(feat, test_y)\n",
    "\n",
    "#     f1, mAP = f1_map(test_y, pred_test, 0.5)\n",
    "#     print('feature net', f1, mAP)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bbc20302",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:20:42.413110Z",
     "start_time": "2021-06-18T22:20:27.859477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf net start 0.4105516296229916 0.33045646957084107\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feat_net = MLP()\n",
    "inf_net = InfNet()\n",
    "energy_net = EnergyNet()\n",
    "feat_net, inf_net, energy_net = tf2torch('./copied.ckpt', feat_net, inf_net, energy_net)\n",
    "\n",
    "optim_inf = torch.optim.Adam(inf_net.parameters(), lr=1e-3, weight_decay=0)\n",
    "optim_energy = torch.optim.Adam(list(energy_net.C1.parameters()) + list(energy_net.c2.parameters()), \n",
    "                                lr=1e-3, weight_decay=0)\n",
    "optim_e  = torch.optim.Adam(list(inf_net.parameters()) + list(energy_net.parameters()), \n",
    "                                lr=1e-3, weight_decay=0)\n",
    "\n",
    "spen = SPEN(feat_net, energy_net, inf_net)\n",
    "pred_test = spen.pred(test_x)\n",
    "best_f1, mAP = f1_map(test_y, pred_test)\n",
    "print('inf net start', best_f1, mAP)\n",
    "\n",
    "phi_energies = []\n",
    "theta_energies = []\n",
    "f1s = [best_f1]\n",
    "for epoch in range(10):\n",
    "\n",
    "    for j, i in enumerate(range(0, 4880, 32)):\n",
    "        if i+32 > 4880:\n",
    "            i = 0\n",
    "        l = np.arange(i, i+32)\n",
    "        data = data_x[l]\n",
    "        # print(data.sum())\n",
    "        label = data_y[l]\n",
    "        \n",
    "        optim_e.zero_grad()\n",
    "        optim_inf.zero_grad()\n",
    "        preds, e_loss, inf_loss, summary = spen.compute_loss(data, label)\n",
    "\n",
    "        inf_loss.backward()\n",
    "\n",
    "        optim_inf.step()\n",
    "\n",
    "        \n",
    "        optim_e.zero_grad()\n",
    "        optim_inf.zero_grad()\n",
    "        preds, e_loss, inf_loss, summary = spen.compute_loss(data, label)\n",
    "        \n",
    "        e_loss.backward()\n",
    "\n",
    "        optim_energy.step()\n",
    "\n",
    "    print(epoch)\n",
    "    \n",
    "#     pred_test = spen.pred(test_x)\n",
    "#     best_f1, mAP = f1_map(test_y, pred_test)\n",
    "#     print('current inf net', best_f1, mAP)\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         feat = feat_net(test_x)\n",
    "#         _, pred_test = energy_net(feat, test_y)\n",
    "\n",
    "#     f1, mAP = f1_map(test_y, pred_test, 0.5)\n",
    "#     print('feature net', f1, mAP)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0203ef0",
   "metadata": {},
   "source": [
    "# phrase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4010f4df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T22:15:43.600724Z",
     "start_time": "2021-06-18T22:15:30.522239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf net start 0.4077304623147065 0.3272108909447864\n",
      "0\n",
      "current inf net 0.4161842068681086 0.32669033678144255\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "1\n",
      "current inf net 0.418357964342694 0.32651885712400663\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "2\n",
      "current inf net 0.4191447379841899 0.3270761622976327\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "3\n",
      "current inf net 0.4196247764621689 0.3271073043555753\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "4\n",
      "current inf net 0.41921874467094966 0.32723173381353665\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "5\n",
      "current inf net 0.4181720907474342 0.32710549376776443\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "6\n",
      "current inf net 0.4187331102869359 0.32743135824273834\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "7\n",
      "current inf net 0.4178384834864306 0.32773200635445077\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "8\n",
      "current inf net 0.41696608064906815 0.32776618015913955\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n",
      "9\n",
      "current inf net 0.4165617157413345 0.327980467555045\n",
      "feature net 0.37872409762358 0.33045646957084107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(spen.inf_net.parameters(), lr=0.00001, weight_decay=0)\n",
    "pred_test = spen.pred(test_x)\n",
    "best_f1, mAP = f1_map(test_y, pred_test)\n",
    "print('inf net start', best_f1, mAP)\n",
    "\n",
    "phi_energies = []\n",
    "theta_energies = []\n",
    "f1s = [best_f1]\n",
    "for epoch in range(10):\n",
    "\n",
    "    for j, i in enumerate(range(0, 4880, 32)):\n",
    "        if i+32 > 4880:\n",
    "            i = 0\n",
    "        l = np.arange(i, i+32)\n",
    "        data = data_x[l]\n",
    "        label = data_y[l]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        inf_loss = spen.inference_loss(data)\n",
    "\n",
    "        inf_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(epoch)\n",
    "    \n",
    "    pred_test = spen.pred(test_x)\n",
    "    best_f1, mAP = f1_map(test_y, pred_test)\n",
    "    print('current inf net', best_f1, mAP)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        feat = feat_net(test_x)\n",
    "        _, pred_test = energy_net(feat, test_y)\n",
    "\n",
    "    f1, mAP = f1_map(test_y, pred_test, 0.5)\n",
    "    print('feature net', f1, mAP)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b40d30",
   "metadata": {},
   "source": [
    "# only inf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}